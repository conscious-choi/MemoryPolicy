import torch
import torch.nn as nn
import torchvision.models as tvm

def _build_resnet(name: str, pretrained: bool, replace_stride_with_dilation):
    fn = getattr(tvm, name)
    # torchvision ë²„ì „ í˜¸í™˜ ì²˜ë¦¬
    try:
        # ìµœì‹  API
        weights = getattr(tvm, f"{name.capitalize()}_Weights").DEFAULT if pretrained else None
        return fn(weights=weights, replace_stride_with_dilation=replace_stride_with_dilation)
    except Exception:
        # êµ¬ API
        return fn(pretrained=pretrained, replace_stride_with_dilation=replace_stride_with_dilation)

class ResNetPatchEmbed(nn.Module):
    """
    ResNet ë°±ë³¸ìœ¼ë¡œ ë§Œë“  íŒ¨ì¹˜ ì„ë² ë”©
    forward(x) -> tokens: (B, N, C), grid_size: (H, W)
    """
    def __init__(
        self,
        resnet: str = "resnet18",         # resnet18, resnet34, resnet50 ë“±
        pretrained: bool = True,
        out_stride: int = 16,             # 32 ë˜ëŠ” 16 ê¶Œì¥
        embed_dim: int = 768,
        norm_layer: str = "ln",           # "ln" ë˜ëŠ” "none"
        freeze_bn: bool = True,
        flatten: bool = False
    ):
        super().__init__()
        assert out_stride in (16, 32), "out_strideì€ 16 ë˜ëŠ” 32ë§Œ ê¶Œì¥"

        # dilation ì„¸íŒ…
        if out_stride == 32:
            replace = [False, False, False] # : ê¸°ë³¸ ë‹¤ìš´ìƒ˜í”Œë§ (ë” ì‘ê³  ì¶”ìƒì )
        else:  # 16
            replace = [False, False, True] # â†’ strideë¥¼ ì—†ì• ê³  dilation=2ë¡œ ëŒ€ì²´ # dilationìœ¼ë¡œ ê³µê°„ í•´ìƒë„ ìœ ì§€ (ë” ì´˜ì´˜í•˜ê³  spatial ì •ë³´ ë§ìŒ)

        backbone = _build_resnet(resnet, pretrained, replace)
        # stem + layer1..4ë§Œ ì‚¬ìš©
        self.stem = nn.Sequential(
            backbone.conv1, backbone.bn1, backbone.relu, backbone.maxpool,
            backbone.layer1, backbone.layer2, backbone.layer3, backbone.layer4
        )
        # in_channelsëŠ” fc in_featuresë¡œ ì–»ì„ ìˆ˜ ìˆìŒ
        in_ch = backbone.fc.in_features
        self.proj = nn.Conv2d(in_ch, embed_dim, kernel_size=1, bias=False)
        self.norm = nn.LayerNorm(embed_dim) if norm_layer == "ln" else nn.Identity()

        # ì•ˆ ì“°ëŠ” ëª¨ë“ˆ ì •ë¦¬
        del backbone.avgpool
        del backbone.fc

        if freeze_bn:
            for m in self.modules():
                if isinstance(m, nn.BatchNorm2d):
                    m.eval()
                    for p in m.parameters():
                        p.requires_grad = False

        self.flatten = flatten

    def forward(self, x: torch.Tensor):
        """
        x: (B, 3, H, W), [0,1] ì •ê·œí™” ê°€ì •
        returns:
          tokens: (B, N, C)
          grid_size: (h, w)
        """
        feat = self.stem(x)          # (B, Cb, h, w)
        feat = self.proj(feat)       # (B, C,  h, w)
        B, C, h, w = feat.shape

        if not self.flatten:
            # ğŸ”¹ spatial map ìœ ì§€
            return feat, (h, w)

        tokens = feat.flatten(2).transpose(1, 2)  # (B, N=h*w, C)
        tokens = self.norm(tokens)
        return tokens, (h, w)
