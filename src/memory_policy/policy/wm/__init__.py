# instruction_memory.py
import torch
import numpy as np
import torch.nn.functional as F
from memory_policy.modules import SigLIP2
from typing import Dict, Tuple, Optional

# ì´ë¯¸ ì •ì˜í•´ ë‘” SigLIP2 í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

class InstructionMemory:
    """
    forward(images, instruction, resnet_patches) í˜¸ì¶œ ì‹œ
    - SigLIP2ë¡œ ì´ë¯¸ì§€ ì„ë² ë”©ê³¼ í…ìŠ¤íŠ¸ ì„ë² ë”© ê³„ì‚°
    - í…ìŠ¤íŠ¸ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ í•˜ë‚˜ë¥¼ ì„ íƒ
    - {instruction: {"siglip_image": ..., "siglip_text": ..., "resnet_patch": ..., "score": ...}} í˜•íƒœë¡œ ì €ì¥
    """

    def __init__(self, siglip: "SigLIP2", store_on_cpu: bool = True):
        self.siglip = siglip
        self.store_on_cpu = store_on_cpu
        # ğŸ”¹ í…ìŠ¤íŠ¸ ì„ë² ë”© ìºì‹œ ì¶”ê°€
        self.text_cache: Dict[str, torch.Tensor] = {}
        # ğŸ”¹ ìµœê³ ì ë§Œ ì €ì¥í•˜ëŠ” ë² ìŠ¤íŠ¸ ë±…í¬
        self.best_bank: Dict[str, Dict[str, torch.Tensor]] = {}

        self.text_cache: Dict[str, torch.Tensor] = {}
        self.best_bank: Dict[str, Dict[str, torch.Tensor]] = {}

    @torch.no_grad()
    def ensure_text_embedding(self, instruction: str) -> torch.Tensor:
        """
        instruction í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìºì‹œí•˜ê³  ë°˜í™˜í•œë‹¤.
        """
        if instruction not in self.text_cache:
            txt_emb = self.siglip.embed_texts(instruction)  # (1, D)
            if self.store_on_cpu:
                txt_emb = txt_emb.cpu()
            self.text_cache[instruction] = txt_emb[0]  # (D,)
        return self.text_cache[instruction]

    @torch.no_grad()
    def update(
        self,
        image_hwc: np.ndarray,
        instruction: str,
        resnet_patch: torch.Tensor,
        bgr: bool = False,
        index_hint: Optional[int] = None,
    ) -> Tuple[float, bool]:
        """
        ìŠ¤íŠ¸ë¦¬ë° ì´ë¯¸ì§€ í•œ ì¥ì„ ë°›ì•„ ë² ìŠ¤íŠ¸ ê°±ì‹ ì„ ì‹œë„í•œë‹¤.

        image_hwc   HWC uint8 numpy
        instruction ë¬¸ìì—´
        resnet_patch (C,H,W) ë˜ëŠ” (1,C,H,W) í…ì„œ
        bgr         OpenCV BGR ì…ë ¥ì´ë©´ True
        index_hint  ì™¸ë¶€ì—ì„œ ì´ í”„ë ˆì„ì˜ ì¸ë±ìŠ¤ë¥¼ ê´€ë¦¬í•˜ê³  ìˆìœ¼ë©´ ë„˜ê¸¸ ìˆ˜ ìˆìŒ

        return
          score        ì´ë²ˆ í”„ë ˆì„ì˜ cosine similarity
          is_best      ì´ë²ˆ í”„ë ˆì„ì´ í˜„ì¬ê¹Œì§€ ìµœê³ ì˜€ëŠ”ì§€ ì—¬ë¶€
        """
        # 1 í…ìŠ¤íŠ¸ ì„ë² ë”© í™•ë³´
        txt = self.ensure_text_embedding(instruction)    # (D,)
        txt_dev = txt.device

        # 2 ì´ë¯¸ì§€ ì„ë² ë”©  ë°°ì¹˜ 1ë¡œ ê³„ì‚°
        img_emb = self.siglip.embed_images(image_hwc, bgr=bgr)  # (1, D)
        if self.store_on_cpu:
            img_emb = img_emb.cpu()

        # 3 similarity
        # txt shape (D,) â†’ (1,D)ë¡œ ë§ì¶° matmul
        score = float((txt.unsqueeze(0) @ img_emb.T).item())

        # 4 resnet_patch ì •ë¦¬
        if not isinstance(resnet_patch, torch.Tensor):
            raise TypeError("resnet_patchëŠ” torch.Tensorì—¬ì•¼ í•©ë‹ˆë‹¤")
        if resnet_patch.dim() == 4:
            if resnet_patch.size(0) != 1:
                raise ValueError("resnet_patchê°€ ë°°ì¹˜ë¼ë©´ ë°°ì¹˜ í¬ê¸°ëŠ” 1ì´ì–´ì•¼ í•©ë‹ˆë‹¤")
            resnet_patch = resnet_patch[0]  # (C,H,W)
        elif resnet_patch.dim() != 3:
            raise ValueError("resnet_patchëŠ” (C,H,W) ë˜ëŠ” (1,C,H,W) ì—¬ì•¼ í•©ë‹ˆë‹¤")

        if self.store_on_cpu:
            resnet_patch = resnet_patch.detach().cpu()

        # 5 ë² ìŠ¤íŠ¸ ê°±ì‹ 
        entry = self.best_bank.get(instruction)
        frame_idx = index_hint if index_hint is not None else int(entry["count"]) + 1 if entry else 0
        is_best = False
        if entry is None or score > float(entry["score"]):
            self.best_bank[instruction] = {
                "siglip_image": img_emb[0].clone(),
                "siglip_text": txt.clone(),
                "resnet_patch": resnet_patch.clone(),
                "score": torch.tensor(score),
                "index": torch.tensor(frame_idx),
                "count": torch.tensor((0 if entry is None else int(entry["count"])) + 1),
            }
            is_best = True
        else:
            # ë² ìŠ¤íŠ¸ ìœ ì§€í•˜ë©´ì„œ countë§Œ ì¦ê°€
            entry["count"] = torch.tensor(int(entry["count"]) + 1)

        return score, is_best

    def get_best(self, instruction: str) -> Optional[Dict[str, torch.Tensor]]:
        """
        í•´ë‹¹ instructionì˜ í˜„ì¬ê¹Œì§€ ë² ìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤.
        ë°˜í™˜ dict í‚¤
          siglip_image  (D,)
          siglip_text   (D,)
          resnet_patch  (C,H,W)
          score         float tensor
          index         int tensor  ì—…ë°ì´íŠ¸ ë‹¹ì‹œ í”„ë ˆì„ ì¸ë±ìŠ¤ íŒíŠ¸
          count         int tensor  ì§€ê¸ˆê¹Œì§€ ì²˜ë¦¬í•œ í”„ë ˆì„ ìˆ˜
        """
        return self.best_bank.get(instruction)

    def clear_instruction(self, instruction: str):
        """
        íŠ¹ì • instructionì˜ ìºì‹œì™€ ë² ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™”í•œë‹¤.
        """
        if instruction in self.text_cache:
            del self.text_cache[instruction]
        if instruction in self.best_bank:
            del self.best_bank[instruction]

    def clear_all(self):
        """
        ëª¨ë“  ìºì‹œì™€ ê²°ê³¼ë¥¼ ì´ˆê¸°í™”í•œë‹¤.
        """
        self.text_cache.clear()
        self.best_bank.clear()

    def state_dict(self):
        return {
            "store_on_cpu": self.store_on_cpu,
            "bank": {k: {kk: vv.clone() for kk, vv in v.items()} for k, v in self.best_bank.items()}
        }

    def load_state_dict(self, state):
        self.store_on_cpu = bool(state.get("store_on_cpu", True))
        bank = state.get("bank", {})
        self.best_bank = {
            k: {kk: (vv.clone() if isinstance(vv, torch.Tensor) else vv) for kk, vv in v.items()} for k, v in bank.items()}


    """from here, memory io"""

    def _stack_bank(self):
        """
        self.best_bankì—ì„œ
        texts: [str]
        txts:  (T, D)
        imgs:  (T, D)
        patches: (T, C, H, W)
        ë¥¼ ë§Œë“ ë‹¤
        """
        if not self.best_bank:
            raise RuntimeError("best_bankì´ ë¹„ì–´ ìˆìŒ")

        texts = list(self.best_bank.keys())
        txts = torch.stack([self.best_bank[t]["siglip_text"] for t in texts], dim=0)
        imgs = torch.stack([self.best_bank[t]["siglip_image"] for t in texts], dim=0)
        patches = torch.stack([self.best_bank[t]["resnet_patch"] for t in texts], dim=0)
        return texts, txts, imgs, patches

    @torch.no_grad()
    def most_similar_text_tuple(self, instruction: str):
        """
        í˜„ì¬ instructionê³¼ í…ìŠ¤íŠ¸ ì„ë² ë”© ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ ê³¼ê±° í•­ëª©ì„ ë°˜í™˜
        return
        best_text, best_score, best_entry(dict)
        """
        query = self.ensure_text_embedding(instruction)           # (D,)
        texts, txts, imgs, patches = self._stack_bank()           # T, (T,D), (T,D), (T,C,H,W)
        query = torch.nn.functional.normalize(query, dim=0)
        txts = torch.nn.functional.normalize(txts, dim=1)

        sims = txts @ query                                      # (T,)
        idx = int(torch.argmax(sims).item())
        best_text = texts[idx]
        best_score = float(sims[idx])
        best_entry = self.best_bank[best_text]
        return best_text, best_score, best_entry

    @torch.no_grad()
    def combine_patches_by_img_similarity(
        self,
        instruction: str,
        topk: int | None = None,
        temperature: float = 0.05,
        return_weights: bool = False,
    ):
        """
        í˜„ì¬ í…ìŠ¤íŠ¸ ì„ë² ë”©ê³¼ ê³¼ê±° ì´ë¯¸ì§€ ì„ë² ë”©ì˜ ìœ ì‚¬ë„ë¡œ íŒ¨ì¹˜ë¥¼ ì„ í˜• ê²°í•©
        return
        mixed_patch (C,H,W)
        (ì„ íƒ) indices(T_sel,), weights(T_sel,)
        """
        # 1 í…ìŠ¤íŠ¸ ì„ë² ë”©ê³¼ ë©”ëª¨ë¦¬ í–‰ë ¬
        query_txt = self.ensure_text_embedding(instruction)      # (D,)
        texts, txts, imgs, patches = self._stack_bank()          # imgs: (T,D), patches: (T,C,H,W)

        # 2 ì ìˆ˜ ê³„ì‚°  txt vs img
        q = torch.nn.functional.normalize(query_txt, dim=0)      # (D,)
        K = torch.nn.functional.normalize(imgs, dim=1)           # (T,D)
        sims = K @ q                                             # (T,)

        # 3 ì„ íƒ ì „ëµ  ìƒìœ„ kë§Œ ì“°ê±°ë‚˜ ì „ì²´ ì‚¬ìš©
        if topk is not None and topk < sims.numel():
            vals, idxs = torch.topk(sims, k=topk, dim=0)
            sims_sel = vals
            patches_sel = patches[idxs]                          # (k,C,H,W)
            idxs_sel = idxs
        else:
            sims_sel = sims
            patches_sel = patches                                # (T,C,H,W)
            idxs_sel = torch.arange(sims.shape[0])

        # 4 ì˜¨ë„ ì†Œí”„íŠ¸ë§¥ìŠ¤ ê°€ì¤‘ì¹˜
        w = torch.softmax(sims_sel / max(1e-6, temperature), dim=0)   # (T_sel,)

        # 5 ì„ í˜• ê²°í•©  Î£ w_i * patch_i
        mixed = torch.tensordot(w, patches_sel, dims=([0],[0]))       # (C,H,W)

        if return_weights:
            return mixed, idxs_sel, w
        return mixed





if __name__ == "__main__":

    sig = SigLIP2(model_id="google/siglip2-base-patch16-224")
    mem = StreamingInstructionMemory(sig)

    instruction = "pick up the red cube"

    # ìŠ¤íŠ¸ë¦¬ë° ë£¨í”„ ê°€ì •
    for t in range(10):
        img = np.random.randint(0, 255, size=(256, 256, 3), dtype=np.uint8)
        res_patch = torch.randn(512, 16, 16)
        score, is_best = mem.update(img, instruction, res_patch, bgr=False, index_hint=t)
        if is_best:
            print(f"[t={t}] new best score {score:.4f}")

    best = mem.get_best(instruction)
    print("final best score", float(best["score"]))
    print("best index", int(best["index"]))
    print("siglip image emb shape", tuple(best["siglip_image"].shape))
    print("resnet patch shape", tuple(best["resnet_patch"].shape))


    # í˜„ì¬ í…ìŠ¤íŠ¸ì™€ ê°€ì¥ ìœ ì‚¬í•œ ê³¼ê±° í…ìŠ¤íŠ¸ ì°¾ê¸°
    best_text, best_score, best_entry = mem.most_similar_text_tuple("insert the peg")

    # í˜„ì¬ í…ìŠ¤íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ê³¼ê±° í‚¤í”„ë ˆì„ íŒ¨ì¹˜ë“¤ì„ ì´ë¯¸ì§€ ìœ ì‚¬ë„ë¡œ í˜¼í•©
    mixed_patch, idxs, weights = mem.combine_patches_by_img_similarity(
        "insert the peg", topk=4, temperature=0.07, return_weights=True
    )


    """
    1. state_dict
        í˜„ì¬ ê°ì²´ì˜ í•µì‹¬ ìƒíƒœë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
        í¬í•¨ ë‚´ìš©
        store_on_cpu ì„¤ì •ê°’
        best_bankì˜ ê¹Šì€ ë³µì‚¬ë³¸
        vv.clone()ì„ ì¨ì„œ í…ì„œê°€ ì›ë³¸ê³¼ ë©”ëª¨ë¦¬ë¥¼ ê³µìœ í•˜ì§€ ì•Šë„ë¡ ì•ˆì „í•˜ê²Œ ë³µì‚¬
        í…ì„œê°€ ì•„ë‹Œ ê°’ì€ ê·¸ëŒ€ë¡œ ë„£ìŒ
    2. load_state_dict
        state_dictë¡œë¶€í„° ê°ì²´ ìƒíƒœë¥¼ ë³µì›
        í¬í•¨ ë‚´ìš©
        store_on_cpu ê°’ì„ ë³µì›
        bankì— ë“¤ì–´ ìˆëŠ” í•­ëª©ìœ¼ë¡œ best_bank ì¬êµ¬ì„±
        í…ì„œëŠ” clone()ìœ¼ë¡œ ìƒˆ í…ì„œë¡œ ë§Œë“¤ì–´ ì°¸ì¡° ê´€ê³„ë¥¼ ëŠìŒ
        í…ì„œê°€ ì•„ë‹Œ ê°’ì€ ê·¸ëŒ€ë¡œ ë³µì‚¬
    3. ì™œ cloneì„ ì“°ë‚˜
        ì €ì¥ëœ í…ì„œë¥¼ ê·¸ëŒ€ë¡œ ì°¸ì¡°í•˜ë©´ ì´í›„ ìˆ˜ì • ì‹œ ì›ë³¸ê³¼ ì €ì¥ë³¸ì´ ì„œë¡œ ì˜í–¥ì„ ì£¼ëŠ” ë¬¸ì œê°€ ìƒê¸¸ ìˆ˜ ìˆì–´ìš”
        clone()ìœ¼ë¡œ ë¶„ë¦¬í•´ ë¶€ì‘ìš©ì„ ë°©ì§€í•©ë‹ˆë‹¤

    # ì €ì¥
    state = mem.state_dict()
    torch.save(state, "mem_state.pt")

    # ë¡œë“œ
    state = torch.load("mem_state.pt", map_location="cpu")
    mem.load_state_dict(state)
    """